{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\n# --- S1: Prepare the Data ---\n# Load the MNIST dataset (handwritten digits)\nmnist = tf.keras.datasets.mnist\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# Normalization: Scale pixels to a range of 0 to 1\nx_train, x_test = x_train / 255.0, x_test / 255.0\n\n# --- S2: Initialize & Define Model Architecture ---\n# This includes S2 (initialization happens automatically inside Keras layers)\nmodel = models.Sequential([\n    layers.Flatten(input_shape=(28, 28)), # Flatten 2D image to 1D vector\n    layers.Dense(128, activation='relu'),   # Hidden layer with ReLU activation\n    layers.Dropout(0.2),                  # Regularization to prevent overfitting\n    layers.Dense(10, activation='softmax') # Output layer (10 classes for digits 0-9)\n])\n\n# --- S4 & S6: Calculate Loss & Choose Optimizer ---\nmodel.compile(optimizer='adam',                # Step 6: Adam (Gradient Descent Variant)\n              loss='sparse_categorical_crossentropy', # Step 4: Loss Function\n              metrics=['accuracy'])\n\n# --- S3, S5, & S7: Forward Prop, Backprop, and Iterating Over Epochs ---\n# The .fit() function handles Forward Prop, Backprop, and Updates automatically\nprint(\"Starting Training...\")\nmodel.fit(x_train, y_train, epochs=5) # Step 7: Iterate for 5 epochs\n\n# --- S8: Evaluate the Loop ---\nprint(\"\\nEvaluating on Test Data:\")\ntest_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)\nprint(f'\\nTest Accuracy: {test_acc*100:.2f}%')\n\n# --- S9: Deployment (Saving the Model) ---\nmodel.save('my_mnist_model.h5')\nprint(\"\\nModel saved as my_mnist_model.h5\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-19T16:04:25.614925Z","iopub.execute_input":"2026-01-19T16:04:25.615225Z","iopub.status.idle":"2026-01-19T16:05:16.101757Z","shell.execute_reply.started":"2026-01-19T16:04:25.615191Z","shell.execute_reply":"2026-01-19T16:05:16.101090Z"}},"outputs":[{"name":"stderr","text":"2026-01-19 16:04:29.142127: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768838669.566443      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768838669.679138      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768838670.770437      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768838670.770488      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768838670.770491      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768838670.770494      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\nI0000 00:00:1768838690.254442      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1768838690.255174      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Starting Training...\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1768838693.744585     121 service.cc:152] XLA service 0x7de1b4004240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1768838693.744617     121 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1768838693.744620     121 service.cc:160]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1768838694.078262     121 cuda_dnn.cc:529] Loaded cuDNN version 91002\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  78/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5578 - loss: 1.5216","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1768838695.649256     121 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8639 - loss: 0.4804\nEpoch 2/5\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9541 - loss: 0.1569\nEpoch 3/5\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9661 - loss: 0.1115\nEpoch 4/5\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9736 - loss: 0.0854\nEpoch 5/5\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9768 - loss: 0.0730\n\nEvaluating on Test Data:\n313/313 - 2s - 5ms/step - accuracy: 0.9755 - loss: 0.0767\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\nTest Accuracy: 97.55%\n\nModel saved as my_mnist_model.h5\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import tensorflow as tf\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# --- S1: Prepare Data ---\ndata = fetch_california_housing()\nX, y = data.data, data.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# --- S2: Initialize ---\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(64, activation='relu', input_shape=(8,)), # 8 features\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dense(1) # Single numeric output for price\n])\n\n# --- S4 & S6: Loss & Optimizer ---\nmodel.compile(optimizer='adam', loss='mse') # Mean Squared Error for regression\n\n# --- S3, S5, S7: Training ---\nmodel.fit(X_train, y_train, epochs=20, validation_split=0.2)\n\n# --- S8: Evaluate ---\nmse = model.evaluate(X_test, y_test)\nprint(f\"Mean Squared Error: {mse}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T16:11:03.894930Z","iopub.execute_input":"2026-01-19T16:11:03.895497Z","iopub.status.idle":"2026-01-19T16:11:27.893781Z","shell.execute_reply.started":"2026-01-19T16:11:03.895468Z","shell.execute_reply":"2026-01-19T16:11:27.893085Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 2.2897 - val_loss: 0.4372\nEpoch 2/20\n\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4450 - val_loss: 0.3890\nEpoch 3/20\n\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4103 - val_loss: 0.3964\nEpoch 4/20\n\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4136 - val_loss: 0.3514\nEpoch 5/20\n\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3983 - val_loss: 0.3485\nEpoch 6/20\n\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3487 - val_loss: 0.3373\nEpoch 7/20\n\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3410 - val_loss: 0.3423\nEpoch 8/20\n\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3458 - val_loss: 0.3238\nEpoch 9/20\n\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3270 - val_loss: 0.3106\nEpoch 10/20\n\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3258 - val_loss: 0.3255\nEpoch 11/20\n\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3460 - val_loss: 0.3327\nEpoch 12/20\n\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3228 - val_loss: 0.3267\nEpoch 13/20\n\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3983 - val_loss: 0.2961\nEpoch 14/20\n\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3079 - val_loss: 0.3164\nEpoch 15/20\n\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2944 - val_loss: 0.2932\nEpoch 16/20\n\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2951 - val_loss: 0.3071\nEpoch 17/20\n\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2922 - val_loss: 0.2920\nEpoch 18/20\n\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2974 - val_loss: 0.2896\nEpoch 19/20\n\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2853 - val_loss: 0.3003\nEpoch 20/20\n\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3534 - val_loss: 0.2888\n\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2980\nMean Squared Error: 0.3010346293449402\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}